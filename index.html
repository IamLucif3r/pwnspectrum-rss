
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>pwnspectrum Tech Digest</title>
<style>
	body { font-family: "Courier New", monospace; background:#0d1117; color:#c9d1d9; margin:0; }
	.centered {
		max-width: 700px;
		margin: 40px auto;
		background: #161b22;
		border-radius: 12px;
		box-shadow: 0 0 24px #000a;
		padding: 32px 24px;
	}
	h1 { text-align:center; color:#58a6ff; }
	h2 { color:#39d353; border-bottom:1px solid #30363d; padding-bottom:5px; }
	.segment { margin-top:40px; }
	.article { border-bottom:1px solid #30363d; padding:24px 0; }
	.content { }
	.tech-jargon {
		border-bottom: 1px dotted #ff7b72;
		cursor: help;
		text-decoration: none;
		color: #ff7b72;
		position: relative;
	}
	.tech-jargon:hover .jargon-expl {
		display: block;
	}
	.jargon-expl {
		display: none;
		position: absolute;
		left: 0;
		background: #21262d;
		color: #c9d1d9;
		padding: 8px 12px;
		border-radius: 6px;
		box-shadow: 0 2px 8px #000a;
		z-index: 10;
		min-width: 180px;
		max-width: 320px;
		font-size: 0.95em;
		margin-top: 6px;
	}
	@media (max-width: 800px) {
		.centered { max-width: 98vw; padding: 8vw 2vw; }
	}
</style>
</head>
<body>
<div class="centered">
<h1>pwnspectrum Tech Digest</h1>

<div class="segment">
	<h2>AI &amp; Prompt Injection</h2>
	
	<div class="article">
		<div class="content">
			<h3>AI-aided malvertising: Exploiting a chatbot to spread scams</h3>
			<p>Hackers weaponized an AI chatbot – dubbed ‘Grokking’ – to launch sophisticated <span class="tech-jargon">malvertising<span class="jargon-expl">Using malicious advertising to spread malware</span></span> campaigns, silently promoting phishing scams. It’s a chilling reminder of AI’s potential for misuse.</p>
			<div class="source">
				Source: <a href="https://www.welivesecurity.com/en/social-media/ai-aided-malvertising-chatbot-scams/" target="_blank">https://www.welivesecurity.com/feed/</a> | Published: 13 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Whisper Leak uses a side channel attack to eavesdrop on encrypted AI conversations</h3>
			<p><div id="remove_no_follow"><div class="grid grid--cols-10@md grid--cols-8@lg article-column">  <div class="col-12 col-10@md col-6@lg col-start-3@lg"><div class="article-column__content"><section class="wp-block-bigbite-multi-title"><div class="container"></div></section><p>Researchers at Microsoft have revealed a new side channel attack named Whisper Leak that can reveal the topic of encrypted conversations between users and language models, even without access to the underlying text.</p><p>The discovery highlights a growing blind spot in AI security where encryption alone no longer guarantees privacy in model interactions.</p><p>Microsofts Security Defender Security Research team <a href="https://www.microsoft.com/en-us/security/blog/2025/11/07/whisper-leak-a-novel-side-channel-cyberattack-on-remote-language-models/" target="_blank" rel="noreferrer noopener">said</a> that attackers are in a position to exploitlarge language models that use metadata such as network packet sizes and timings. For instance, a nation-state actor at the internet service provider layer, someone on the local network, or someone connected to the same Wi-Fi router can observe the encrypted traffic and use it to infer if the users prompt is on a specific topic.</p><h2 class="wp-block-heading" id="metadata-becomes-the-new-attack-surface">Metadata becomes the new attack surface</h2><p>Unlike traditional data breaches or model leaks, Whisper Leak exploits a <a href="https://www.csoonline.com/article/567149/what-is-a-side-channel-attack-how-these-end-runs-around-encryption-put-everyone-at-risk.html?utm=hybrid_search">side channel</a> in network communication rather than a flaw in encryption itself.</p><p>LLM services generate responses step by step, by producing one token at a time instead of the entire response at once. Also, the communications with AI-powered chatbots are often encrypted with HPPS over TLS (HTTPS), ensuring the authenticity of the server and security through encryption.</p><p>But while the Transport Layer Security successfully encrypts the content of communications, it leaks the size of the underlying data chunks being transmitted. For an LLM that streams responses token by token, this size information reveals patterns about the tokens being generated.</p><p>Combined with timing information between packets, these leaked patterns form the basis of the Whisper Leak attack as sufficient information is leaked to enable topic classification, explained Microsoft Defender Security Team in the <a href="https://arxiv.org/pdf/2511.03675" target="_blank" rel="noreferrer noopener">technical report</a>.</p><p>These are not usual data breaches either. They do not steal the files directly; they observe what is happening around the data, said <a href="https://www.primuspartners.in/team/devroop-dhar" target="_blank" rel="noreferrer noopener">Devroop Dhar</a>, co-founder &amp; MD at Primus Partners. They dont have to break encryption or code. What they do instead is look for small clues; timing, lags, maybe how quickly a system answers, and from that, they try to understand whats going on inside. Its very technical and tough to catch when its happening, he added.</p><h2 class="wp-block-heading" id="inside-microsofts-proof-of-concept">Inside Microsofts proof-of-concept</h2><p>Researchers at Microsoft simulated a real-world scenario in which the adversary could observe encrypted traffic but not decrypt it. They chose legality of money laundering as the target topic for the proof-of-concept.</p><p>For positive samples, the team used alanguage modelto generate 100 semantically similar variants of questions about this topic. For negativenoisesamples,it randomly sampled 11,716 unrelated questions from the Quora Questions Pair dataset, covering a wide variety of topics.</p><p>Once done, the collected data was trained using LightGBM, Bi-LSTM, and BERT-based models, evaluated intime-only, packet-size only, or both modes.</p><p>The research team demonstrated the attack across 28 popular LLMs from major providers, and achieved near-perfect classification (often &gt;98% Area Under the Precision-Recall Curve (AUPRC)) and high precision even at extreme class imbalance (10,000:1 noise-to-target ratio). For many models, they achieved 100% precision in identifying sensitive topics while recovering 5-20% of target conversations, noted the report.</p><h2 class="wp-block-heading" id="plugging-the-leaks">Plugging the leaks</h2><p>The findings were shared with <a href="https://www.networkworld.com/article/4083656/openai-spends-even-more-money-it-doesnt-have.html?utm=hybrid_search">OpenAI</a>, <a href="https://www.networkworld.com/article/3821150/cisco-launches-ai-renewals-agent-with-mistral-ai.html?utm=hybrid_search">Mistral</a>, Microsoft, and <a href="https://www.networkworld.com/article/3608660/musks-xai-shifts-ai-server-business-from-struggling-supermicro-to-dell.html?utm=hybrid_search">xAI</a>, and mitigation measures were implemented to minimise the risk. To mitigate the effectiveness of cyberattacks, OpenAI, andlater MicrosoftAzure, added a random sequence of text of variable length to each response.</p><p>This obfuscation field masked the length of each token, reducing the attacks effectiveness. Similarly, Mistral included a new parameter called p that had a similar effect.</p><h2 class="wp-block-heading" id="cisos-next-frontier">CISOs next frontier</h2><p>Even if the attack doesnt expose the exact prompt or content of a conversation, it can accurately classify its subject or intent, putting enterprises at major risk.</p><p>If an LLM is just handling public data, it is fine. But if it is processing data like client records, internal documents, financial data, etc, then even a small leak matters. The bigger worry is for companies that run their own AI models or connect them to cloud APIs. Like banks, healthcare, legal firms, defence, where data sensitivity is too high, Dhar said.</p><p>While it is the AI providers that will have to address the issue, Microsoft researchers recommendations include avoiding discussing highly sensitive topics over AI chatbots when on untrusted networks, using VPN services for adding an additional layer of protection, opting for providers that have already implemented mitigation, and using non-streaming models of large language model providers.</p><p>Dhar pointed out that most AI security checklists do not even mention side channels yet. CISOs need to start asking their teams and vendors how they test for these kinds of probable issues.</p><p>Also, in order to be defensive, we need to keep models isolated, add a bit of random delay so timing data is not predictable, and watch for weird or repeated queries that look like probing. Basically, we need to treat the AI pipeline the way we would treat a critical server, by following a few simple steps like logging it, segmenting it, and not assuming that it is invisible just because it is encrypted, he added. Over time, we will need proper <a href="https://www.csoonline.com/article/3965405/generative-ai-is-making-pen-test-vulnerability-remediation-much-worse.html?utm=hybrid_search">AI pen-testing</a>, like what happened when cloud APIs first became mainstream. It is the same pattern, once the tech matures, attackers get creative and then security always has to catch up, he noted.</p></div></div></div></div></p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4087335/whisper-leak-uses-a-side-channel-attack-to-eavesdrop-on-encrypted-ai-conversations.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 10 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>The AI Fix #73: Google Gemini is a gambling addict, and how to poison an AI</h3>
			<p>Google’s Gemini is exhibiting alarming AI gambling behavior, mirroring pathological tendencies – and it’s shockingly easy to exploit! Learn how vulnerabilities are emerging in LLMs and how to potentially weaponize them.</p>
			<div class="source">
				Source: <a href="https://grahamcluley.com/the-ai-fix-73/" target="_blank">https://www.grahamcluley.com/feed/</a> | Published: 21 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Researchers trick ChatGPT into prompt injecting itself</h3>
			<p>AI chatbots are surprisingly vulnerable! Researchers found seven ways to trick ChatGPT into leaking private data – including embedding malicious instructions in web comments and using image URLs to reconstruct responses. Attackers can chain prompt injections, exploiting long-term memory to persistently deliver harmful commands. It’s a chilling reminder of the risks of interacting with AI.</p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4086965/researchers-trick-chatgpt-into-prompt-injecting-itself.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 10 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>The AI Fix #74: AGI, LLM brain rot, and how to scam an AI browser</h3>
			<p>Forget selfie struggles! This episode dives into AI's unsettling potential – from AGI ambitions with a bizarre influencer crew to risky AI browser trust issues. Buckle up for a wild ride.</p>
			<div class="source">
				Source: <a href="https://grahamcluley.com/the-ai-fix-74/" target="_blank">https://www.grahamcluley.com/feed/</a> | Published: 28 Oct 2025
			</div>
		</div>
	</div>
	
</div>

<div class="segment">
	<h2>Malware &amp; Ransomware</h2>
	
	<div class="article">
		<div class="content">
			<h3>Patch Tuesday, October 2025 End of 10 Edition</h3>
			<p>Hackers are already hitting Windows 10 with three <span class="tech-jargon">actively exploited<span class="jargon-expl">being used by attackers right now</span></span> vulnerabilities – Patch Tuesday just got serious. Microsoft’s dropping support for 10, so upgrade now!</p>
			<div class="source">
				Source: <a href="https://krebsonsecurity.com/2025/10/patch-tuesday-october-2025-end-of-10-edition/" target="_blank">https://krebsonsecurity.com/feed/</a> | Published: 14 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Malicious npm packages contain Vidar infostealer</h3>
			<p>Threat actors are weaponizing npm packages, like the recent ‘Vidar’ infostealer, by disguising malicious code as legitimate libraries. Developers need to actively vet third-party modules and implement robust Software Bills of Materials (<span class="tech-jargon">SBOM<span class="jargon-expl">Software Bill of Materials - A comprehensive list of all the components within a software application.</span></span>s) to mitigate this supply chain attack risk.</p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4086415/malicious-npm-packages-contain-vidar-infostealer-2.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 07 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Vibe-coded ransomware proof-of-concept ended up on Microsofts marketplace</h3>
			<p><div id="remove_no_follow"><div class="grid grid--cols-10@md grid--cols-8@lg article-column">  <div class="col-12 col-10@md col-6@lg col-start-3@lg"><div class="article-column__content"><section class="wp-block-bigbite-multi-title"><div class="container"></div></section><p>In a suspected test effort, unknown actors have successfully embedded a strain of ransomware-style behavior, dubbed Ransomvibe, into extensions listed for Visual Studio Code.</p><p>According to Secure Annex findings, the malicious code published to the VSCode extension marketplace was clearly <a href="https://www.csoonline.com/article/4053635/when-ai-nukes-your-database-the-dark-side-of-vibe-coding.html" target="_blank">vibe-coded</a>, lacking any real sophistication.</p><p>This is not a sophisticated example as the command and control server code was accidentally(?) included in the published extensions package along with decryption tools, said Secure Annexs John Tuckner, adding that the extension included a blatantly malicious marketplace description.</p><p>Despite the extension carrying obvious red flags, the code slipped past Microsofts review filters and remains available even after being reported, Tuckner said in an <a href="https://x.com/tuckner/status/1986232371650183204" target="_blank" rel="noreferrer noopener">X post</a>.</p><p>The malicious code includes file encryption and theft capabilities.</p><h2 class="wp-block-heading"><a></a>Obvious AI-slop in the Ransomvibe POC</h2><p>According to Tuckner, the malicious Visual Studio Code extension, named suspicious VSX and published under the equally telling alias Suspicious publisher, was hiding its payload in plain sight.</p><p>The extension, listed as suspublisher18.susvsex, included package.json that automatically activated on any event, even during installation, while offering command palette utilities to test command and control functions. Inside the extension.js entrypoint, researchers found hardcoded variables including server URL, encryption keys, C2 destinations, and polling intervals. Most of these variables carried comments indicating the code was generated through AI.</p><p>When triggered, the extension initiates compression and encryption of files inside a designated directory, uploading them to a remote command server.</p><p>Tucker <a href="https://secureannex.com/blog/ransomvibe/" target="_blank" rel="noreferrer noopener">noted</a> that the target directory was configured for testing, but could easily be swapped for a real filesystem path in a future update or by remote command. The extension contained two decryptors, one in Python and one in Node, along with a hardcoded decryption key, eliminating the possibility of malicious intent.</p><h2 class="wp-block-heading" id="extension-pointed-to-a-github-based-c2">Extension pointed to a GitHub-based C2</h2><p>Ransomvibe deployed a rather unusual GitHub-based command-and-control (C2) infrastructure, instead of relying on traditional C2 servers. The extension used a private GitHub repository to receive and execute commands. It routinely checked for new commits in a file named index.html, executed the embedded commands, and then wrote the output back into requirements.txt using a GitHub Personal Access Token (PAT) bundled inside the extension.</p><p>Apart from enabling exfiltration of host data, this C2 behavior exposed the attackers own environment, traces of which pointed to a GitHub user in Baku, whose time zone matched the system data logged by the malware itself.</p><p>Secure Annex calls this a textbook example of AI-assisted malware development, featuring misplaced source files (including decryption tools and the attackers C2 code) and a README.md file that explicitly describes its malicious functionality. But Tuckner argues that the real failure lies in Microsofts marketplace review system, which failed to flag the extension.</p><p>Microsoft said it had removed the extension from the marketplace. Every extensions page in the marketplace contains a Report Abuse link, and the company investigates all reports, it said; where the malicious nature of an extension is verified, or where a vulnerability is found in an extension dependency, the extension is removed from the marketplace, added to a block list, and automatically uninstalled by VS Code, it said. Enterprises wishing to prevent access to the marketplace can do so by <a href="https://code.visualstudio.com/docs/setup/network#_common-hostnames" target="_blank" rel="noreferrer noopener">blocking specific endpoints</a>, it added.</p><p>Recent incidents have shown that malicious or careless extensions are becoming a recurring problem in the Visual Studio Code ecosystemwith some <a href="https://www.csoonline.com/article/4074948/threat-actors-are-spreading-malicious-extensions-via-vs-marketplaces-2.html">leaking credentials</a> and others quietly <a href="https://www.csoonline.com/article/4072829/tigerjacks-malicious-vscode-extensions-mine-steal-and-stay-hidden.html">stealing code or mining</a> cryptocurrency. Apart from a list of IOCs shared, Secure Annex released the Secure Annex Extension Manager, a tool designed to block known malicious extensions and inventory installed add-ons across an organization.</p></div></div></div></div></p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4086639/vibe-coded-ransomware-proof-of-concept-ended-up-on-microsofts-marketplace.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 07 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Nikkeis Slack breach leaks sensitive data from more than 17,000 users</h3>
			<p><div id="remove_no_follow"><div class="grid grid--cols-10@md grid--cols-8@lg article-column">  <div class="col-12 col-10@md col-6@lg col-start-3@lg"><div class="article-column__content"><section class="wp-block-bigbite-multi-title"><div class="container"></div></section><p>Japanese media company Nikkei has confirmed that a security breach of its Slack accounts has potentially leaked highly sensitive information from more than 17,000 of its users. Consultants point to the incident as yet another reminder of the dangers when non-corporate devices are allowed to access confidential corporate data.</p><p>An employees personal computer was infected with a virus, leading to the leakage of Slack authentication credentials. It is believed that this information was used to gain unauthorized access to employee accounts, Nikkei said in <a href="https://www.nikkei.co.jp/nikkeiinfo/en/news/announcements/1394.html" target="_blank" rel="noreferrer noopener">a published statement</a>. The incident was identified in September and countermeasures such as changing passwords were implemented. Potentially leaked information includes the names, email addresses, and chat histories for 17,368 individuals registered on Slack.</p><p>The Nikkei statement added Considering the incidents significance and to ensure transparency, we voluntarily reported it to [Japans] <a href="https://www.ppc.go.jp/en/" target="_blank" rel="noreferrer noopener">Personal Information Protection Commission</a>. No leakage of information related to sources or reporting activities has been confirmed.</p><p>Cybersecurity consultant <a href="https://formergov.com/directory/brianlevine" target="_blank" rel="noreferrer noopener">Brian Levine</a>, a former federal prosecutor who today serves as executive director of FormerGov, a directory of former government and military specialists, stressed that this is part of an ongoing trend of Slack breaches.</p><p>There is often increased risk when employees or contractors access company resources from non-company-managed devices. Recent attacks against Okta, MGM Resorts, and others have been linked to such unmanaged access, Levine said, adding that last year, an attacker exfiltrated more than [1 terabyte] of internal data from Disneys Slack environment when a contractor had accessed Slack from an unmanaged device, bypassing monitoring tools.</p><p><a href="https://www.infotech.com/profiles/erik-avakian" target="_blank" rel="noreferrer noopener">Erik Avakian</a>, technical counselor at Info-Tech Research Group, noted that one of the most concerning things about attacks similar to the Nikkei breach is that the attackers are often able to easily bypass MFA defenses.</p><p>An employees computer gets hit by malware designed to steal credentials. The malware grabs Slack session tokens and cookies, then sends them to attacker command and control servers, Avakian said. With those stolen and likely active tokens, the attacker is able to log into Slack from their own device and access private channels and chat history without even triggering a multi-factor authentication prompt, since they reused an already-authenticated session.</p><p>Avakian said that the nature of these attacks suggests that enterprise CISOs should consider procedural changes.</p><p>This kind of attack would give threat actors broad access to channels and integrations, which made the impact worse. Weaknesses around this incident shine a light on unmanaged or poorly protected devices, long-lived tokens, and not enough logging or alerts for suspicious sessions, Avakian said. Organizations can learn from these types of incident, and those using Slack, or any other widely used communications platform similar to Slack, should maintain a policy for revoking active sessions and refreshing tokens for affected users routinely, forcing password resets and rotating API tokens.</p><p><a href="https://www.linkedin.com/in/jeffreyeman/" target="_blank" rel="noreferrer noopener">Jeff Man</a>, a senior information security consultant with Online Business Systems, pointed out, the larger discussion should be on the failings of the Nikkei IT/IS program to protect against some sort of attack that targeted its employees. Why are employees allowed to use Slack on personal devices?</p><p>So this is really an issue of risk management, Man said. In the case of Nikkei, it appears the exploitation was elsewhere [on the system]. The initial access allowed the miscreants to use credentials to gain access to Slack. Thats not a compromise of Slack itself, thats a compromise of employee account authentication.</p><p><a href="https://thecyberdr.com/#about" target="_blank" rel="noreferrer noopener">Stephen Boyce</a>, security consultant and CEO of The Cyber Dr., said the Nikkei incident represents what happens when someone uses a personal device to get into work systems. Once that device gets hit with malware, its game over for the credentials. The part that worries me is this could happen anywhere. People forget how much sensitive stuff ends up in Slack: messages, files, links, sometimes even credentials. Once someone has that, they can poke around pretty freely.</p><p>To me, its just another reminder that zero trust has to go all the way out to the edge, not just the network. Youve got to know the device, use MFA tied to managed hardware, and control what data lives in those SaaS tools, Boyce said. You may be also asking Well, do we do away with BYOD all together? And the short answer is no but we do need to look at ways we can secure the workforce beyond company issued assets.</p></div></div></div></div></p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4086100/nikkeis-slack-breach-leaks-sensitive-data-from-more-than-17000-users.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 06 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Why cant enterprises get a handle on the cloud misconfiguration problem?</h3>
			<p>Enterprises are struggling with cloud misconfigurations, leaving data exposed due to defaults and human error. 28% of organizations had breaches last year, often stemming from unsecured S3 buckets or lack of MFA. AI can help, but fixing this requires a fundamental shift: start secure from day one, implement controls like least privilege and encryption, and continuously monitor for vulnerabilities. It’s not just about tools, it’s about process.</p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4083736/why-cant-enterprises-get-a-handle-on-the-cloud-misconfiguration-problem.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 07 Nov 2025
			</div>
		</div>
	</div>
	
</div>

<div class="segment">
	<h2>Security Research &amp; Breaches</h2>
	
	<div class="article">
		<div class="content">
			<h3>Critical React Native CLI Flaw Exposed Millions of Developers to Remote Attacks</h3>
			<p>A sneaky bug in the React Native CLI is letting attackers remotely execute commands on your machine – potentially exposing millions of developers. Patch it now!</p>
			<div class="source">
				Source: <a href="https://thehackernews.com/2025/11/critical-react-native-cli-flaw-exposed.html" target="_blank">https://feeds.feedburner.com/TheHackersNews</a> | Published: 04 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Malicious npm packages contain Vidar infostealer</h3>
			<p>Threat actors are injecting malware – specifically the Vidar infostealer – into open-source npm packages. This tactic, dubbed typosquatting, tricks developers into installing malicious libraries mimicking legitimate ones.  Protect your apps by diligently vetting third-party modules and implementing software bill of materials (<span class="tech-jargon">SBOM<span class="jargon-expl">Software Bill of Materials - A detailed inventory of all software components within an application.</span></span>s) for continuous tracking and security.</p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4086415/malicious-npm-packages-contain-vidar-infostealer-2.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 07 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Hacking the World Poker Tour: Inside ClubWPT Golds Back Office</h3>
			<p>A rogue actor exploited a ClubWPT Gold back-office vulnerability in 2025, gaining unauthorized access to the platform’s core administrative functions. Seriously, a complete system <span class="tech-jargon">compromise<span class="jargon-expl">Unauthorized access to a system</span></span>—a juicy <span class="tech-jargon">zero-day<span class="jargon-expl">A previously unknown vulnerability</span></span>!</p>
			<div class="source">
				Source: <a href="https://samcurry.net/hacking-clubwpt-gold" target="_blank">https://0dayfans.com/feed.rss</a> | Published: 12 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Whisper Leak uses a side channel attack to eavesdrop on encrypted AI conversations</h3>
			<p><div id="remove_no_follow"><div class="grid grid--cols-10@md grid--cols-8@lg article-column">  <div class="col-12 col-10@md col-6@lg col-start-3@lg"><div class="article-column__content"><section class="wp-block-bigbite-multi-title"><div class="container"></div></section><p>Researchers at Microsoft have revealed a new side channel attack named Whisper Leak that can reveal the topic of encrypted conversations between users and language models, even without access to the underlying text.</p><p>The discovery highlights a growing blind spot in AI security where encryption alone no longer guarantees privacy in model interactions.</p><p>Microsofts Security Defender Security Research team <a href="https://www.microsoft.com/en-us/security/blog/2025/11/07/whisper-leak-a-novel-side-channel-cyberattack-on-remote-language-models/" target="_blank" rel="noreferrer noopener">said</a> that attackers are in a position to exploitlarge language models that use metadata such as network packet sizes and timings. For instance, a nation-state actor at the internet service provider layer, someone on the local network, or someone connected to the same Wi-Fi router can observe the encrypted traffic and use it to infer if the users prompt is on a specific topic.</p><h2 class="wp-block-heading" id="metadata-becomes-the-new-attack-surface">Metadata becomes the new attack surface</h2><p>Unlike traditional data breaches or model leaks, Whisper Leak exploits a <a href="https://www.csoonline.com/article/567149/what-is-a-side-channel-attack-how-these-end-runs-around-encryption-put-everyone-at-risk.html?utm=hybrid_search">side channel</a> in network communication rather than a flaw in encryption itself.</p><p>LLM services generate responses step by step, by producing one token at a time instead of the entire response at once. Also, the communications with AI-powered chatbots are often encrypted with HPPS over TLS (HTTPS), ensuring the authenticity of the server and security through encryption.</p><p>But while the Transport Layer Security successfully encrypts the content of communications, it leaks the size of the underlying data chunks being transmitted. For an LLM that streams responses token by token, this size information reveals patterns about the tokens being generated.</p><p>Combined with timing information between packets, these leaked patterns form the basis of the Whisper Leak attack as sufficient information is leaked to enable topic classification, explained Microsoft Defender Security Team in the <a href="https://arxiv.org/pdf/2511.03675" target="_blank" rel="noreferrer noopener">technical report</a>.</p><p>These are not usual data breaches either. They do not steal the files directly; they observe what is happening around the data, said <a href="https://www.primuspartners.in/team/devroop-dhar" target="_blank" rel="noreferrer noopener">Devroop Dhar</a>, co-founder &amp; MD at Primus Partners. They dont have to break encryption or code. What they do instead is look for small clues; timing, lags, maybe how quickly a system answers, and from that, they try to understand whats going on inside. Its very technical and tough to catch when its happening, he added.</p><h2 class="wp-block-heading" id="inside-microsofts-proof-of-concept">Inside Microsofts proof-of-concept</h2><p>Researchers at Microsoft simulated a real-world scenario in which the adversary could observe encrypted traffic but not decrypt it. They chose legality of money laundering as the target topic for the proof-of-concept.</p><p>For positive samples, the team used alanguage modelto generate 100 semantically similar variants of questions about this topic. For negativenoisesamples,it randomly sampled 11,716 unrelated questions from the Quora Questions Pair dataset, covering a wide variety of topics.</p><p>Once done, the collected data was trained using LightGBM, Bi-LSTM, and BERT-based models, evaluated intime-only, packet-size only, or both modes.</p><p>The research team demonstrated the attack across 28 popular LLMs from major providers, and achieved near-perfect classification (often &gt;98% Area Under the Precision-Recall Curve (AUPRC)) and high precision even at extreme class imbalance (10,000:1 noise-to-target ratio). For many models, they achieved 100% precision in identifying sensitive topics while recovering 5-20% of target conversations, noted the report.</p><h2 class="wp-block-heading" id="plugging-the-leaks">Plugging the leaks</h2><p>The findings were shared with <a href="https://www.networkworld.com/article/4083656/openai-spends-even-more-money-it-doesnt-have.html?utm=hybrid_search">OpenAI</a>, <a href="https://www.networkworld.com/article/3821150/cisco-launches-ai-renewals-agent-with-mistral-ai.html?utm=hybrid_search">Mistral</a>, Microsoft, and <a href="https://www.networkworld.com/article/3608660/musks-xai-shifts-ai-server-business-from-struggling-supermicro-to-dell.html?utm=hybrid_search">xAI</a>, and mitigation measures were implemented to minimise the risk. To mitigate the effectiveness of cyberattacks, OpenAI, andlater MicrosoftAzure, added a random sequence of text of variable length to each response.</p><p>This obfuscation field masked the length of each token, reducing the attacks effectiveness. Similarly, Mistral included a new parameter called p that had a similar effect.</p><h2 class="wp-block-heading" id="cisos-next-frontier">CISOs next frontier</h2><p>Even if the attack doesnt expose the exact prompt or content of a conversation, it can accurately classify its subject or intent, putting enterprises at major risk.</p><p>If an LLM is just handling public data, it is fine. But if it is processing data like client records, internal documents, financial data, etc, then even a small leak matters. The bigger worry is for companies that run their own AI models or connect them to cloud APIs. Like banks, healthcare, legal firms, defence, where data sensitivity is too high, Dhar said.</p><p>While it is the AI providers that will have to address the issue, Microsoft researchers recommendations include avoiding discussing highly sensitive topics over AI chatbots when on untrusted networks, using VPN services for adding an additional layer of protection, opting for providers that have already implemented mitigation, and using non-streaming models of large language model providers.</p><p>Dhar pointed out that most AI security checklists do not even mention side channels yet. CISOs need to start asking their teams and vendors how they test for these kinds of probable issues.</p><p>Also, in order to be defensive, we need to keep models isolated, add a bit of random delay so timing data is not predictable, and watch for weird or repeated queries that look like probing. Basically, we need to treat the AI pipeline the way we would treat a critical server, by following a few simple steps like logging it, segmenting it, and not assuming that it is invisible just because it is encrypted, he added. Over time, we will need proper <a href="https://www.csoonline.com/article/3965405/generative-ai-is-making-pen-test-vulnerability-remediation-much-worse.html?utm=hybrid_search">AI pen-testing</a>, like what happened when cloud APIs first became mainstream. It is the same pattern, once the tech matures, attackers get creative and then security always has to catch up, he noted.</p></div></div></div></div></p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4087335/whisper-leak-uses-a-side-channel-attack-to-eavesdrop-on-encrypted-ai-conversations.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 10 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Why cant enterprises get a handle on the cloud misconfiguration problem?</h3>
			<p>Enterprises are drowning in cloud misconfigurations, leaving data exposed due to overlooked defaults and a lack of proactive management.  A staggering 28% of organizations have experienced breaches linked to misconfigured services, with 45% of AWS resources and 63% of GCP resources unsecure.  The key? Prioritize encryption, enforce <span class="tech-jargon">least privilege<span class="jargon-expl">Granting users and systems only the minimum level of access necessary to perform their job functions.</span></span>, and continuously monitor – or face a mounting risk.</p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4083736/why-cant-enterprises-get-a-handle-on-the-cloud-misconfiguration-problem.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 07 Nov 2025
			</div>
		</div>
	</div>
	
</div>

<div class="segment">
	<h2>Tools &amp; Offensive Techniques</h2>
	
	<div class="article">
		<div class="content">
			<h3>Critical React Native CLI Flaw Exposed Millions of Developers to Remote Attacks</h3>
			<p>A sneaky bug in React Native's CLI is letting hackers remotely execute commands on developer machines. Patch it now – this could unlock a serious attack vector.</p>
			<div class="source">
				Source: <a href="https://thehackernews.com/2025/11/critical-react-native-cli-flaw-exposed.html" target="_blank">https://feeds.feedburner.com/TheHackersNews</a> | Published: 04 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>AI-aided malvertising: Exploiting a chatbot to spread scams</h3>
			<p>Attackers hijacked an AI chatbot to generate malicious ads—a cunning move dubbed 'Grokking'. This showcased how AI can be weaponized for sophisticated phishing campaigns, highlighting a new threat vector.</p>
			<div class="source">
				Source: <a href="https://www.welivesecurity.com/en/social-media/ai-aided-malvertising-chatbot-scams/" target="_blank">https://www.welivesecurity.com/feed/</a> | Published: 13 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Truffle Security Co. TruffleHog git arbitrary code execution vulnerability</h3>
			<p><span class="tech-jargon">TruffleHog<span class="jargon-expl">A Git secrets scanning tool.</span></span>, a popular Git secrets scanner, had a nasty surprise – arbitrary code execution! A clever exploit allows attackers to inject and run malicious code directly within the scanner, highlighting a critical vulnerability.</p>
			<div class="source">
				Source: <a href="https://talosintelligence.com/vulnerability_reports/TALOS-2025-2243" target="_blank">https://0dayfans.com/feed.rss</a> | Published: 19 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Runtime bugs break container walls, enabling root on Docker hosts</h3>
			<p><div id="remove_no_follow"><div class="grid grid--cols-10@md grid--cols-8@lg article-column">  <div class="col-12 col-10@md col-6@lg col-start-3@lg"><div class="article-column__content"><section class="wp-block-bigbite-multi-title"><div class="container"></div></section><p>Three newly disclosed high-severity bugs in the runc container runtime let attackers break out of containers despite standard hardening and isolation controls.</p><p>According to Aleksa Sarai, a senior software engineer at SUSE and an OCI board member, the bugs stem from logic flaws in how runc handles writes to certain procfs files, letting attackers inside containers hijack host privileges by abusing masked paths, console bind-mounts, and write gadgets.</p><p>All these vulnerabilities ultimately allow (through different methods) for full container breakouts by bypassing runcs restrictions for writing to arbitrary /proc files, Sarai said in an advisory posted to the oss-sec list.</p><p>Sarai emphasized that while these attacks require custom mount configurations or untrusted images, the threat is very real for containerized systems, especially in orchestrators like Docker or Kubernetes.</p><p>The advisory urges users to update immediately to patched versions or apply the provided patches.</p><h2 class="wp-block-heading"><a></a>Masked-path issue: CVE-2025-31133</h2><p>The first of the trio addresses a masked-path issue in runc where the container runtime replaces a file with a bind-mount to /dev/null, a data sink file on Unix-like systems. If an attacker can instead make /dev/null a symlink to a critical procfs file (e.g., /proc/sys/kernel/core_pattern or /proc/sysrq-trigger), runc inadvertently mounts that target read-write, granting the attacker host access.</p><p>On one variant, runc simply ignores a missing /dev/null and proceeds, which leads to information disclosure via masked files like /proc/kcore or /proc/timer_list, both sensitive kernel-visible interfaces.</p><p>Sarai <a href="https://seclists.org/oss-sec/2025/q4/138" target="_blank" rel="noreferrer noopener">warned</a> that while the attack cannot mount arbitrary host files directly, the methods are sufficient to trigger full container breakout or host crash.</p><p>The flaw, tracked as <a href="https://nvd.nist.gov/vuln/detail/CVE-2025-31133">CVE-2025-31133</a>, affects all known runc versions and has received a severity rating of 7.3 out of 10. It has been fixed in versions 1.2.8, 1.3.3, and 1.4.0-rc.3.</p><h2 class="wp-block-heading"><a></a>Console and Write-Gadget Lurkers: CVE-2025-52565 &amp; CVE-2025-52881</h2><p>The second vulnerability, tracked as <a href="https://nvd.nist.gov/vuln/detail/CVE-2025-52565">CVE-2025-52565</a>, targets /dev/console bind-mount handling. An attacker can replace the target path with a symlink, which will cause runc to bind-mount the wrong target, allowing the attacker to gain write access to procfs paths.</p><p>As with CVE-2025-31133, this happens after pivot_root(2) and so cannot be used to bind-mount host files directly, but an attacker can trick runc into creating a read-write bind-mount of /proc/sys/kernel/core_pattern or /proc/sysrq-trigger, leading to a complete container breakout, Sarai said, adding that versions 1.0.0-rc3 and later remain vulnerable.</p><p>The third flaw (<a href="https://nvd.nist.gov/vuln/detail/CVE-2025-52881" target="_blank" rel="noreferrer noopener">CVE-2025-52881</a>) allows an attacker to bypass Linux Security Modules (LSM) such as SELinux or AppArmor by redirecting writes to procfs files. Once the LSM labels are effectively neutered, writes to host-level procfs become possible, enabling <a href="https://www.csoonline.com/article/4046353/critical-docker-desktop-flaw-allows-container-escape.html">full host compromise</a>.</p><p>Based on our analysis, neither AppArmor nor SELinux can protect against the full version of the redirected write attack, Sarai said.  The container runtime is generally privileged enough to write to arbitrary procfs files, which is more than sufficient to cause a container breakout. </p><p>Using rootless containers can help, as doing so will block most of the inadvertent writes, Sarai added. Additional analysis from Sysdig confirmed that all three flaws require the ability to start containers with custom mount configurations, which can be easily achieved through untrusted container images and Dockerfiles. Exploitation of these flaws can be done by monitoring suspicious symlink behaviors, Sysdig <a href="https://www.sysdig.com/blog/runc-container-escape-vulnerabilities" target="_blank" rel="noreferrer noopener">said</a>. For this, it has added detection rules for its Secure and Falco users.</p></div></div></div></div></p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4087323/runtime-bugs-break-container-walls-enabling-root-on-docker-hosts.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 10 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Researchers trick ChatGPT into prompt injecting itself</h3>
			<p>AI chatbots are surprisingly vulnerable! Researchers at Tenable found seven ways to trick ChatGPT – and its SearchGPT intermediary – into executing malicious prompts. Attackers can inject commands via website comments or poisoned content, leading to data leaks using a clever alphabet of image URLs and hidden Markdown formatting.</p>
			<div class="source">
				Source: <a href="https://www.csoonline.com/article/4086965/researchers-trick-chatgpt-into-prompt-injecting-itself.html" target="_blank">https://www.csoonline.com/feed</a> | Published: 10 Nov 2025
			</div>
		</div>
	</div>
	
</div>

<div class="segment">
	<h2>Zero-Day &amp; Exploits</h2>
	
	<div class="article">
		<div class="content">
			<h3>Critical React Native CLI Flaw Exposed Millions of Developers to Remote Attacks</h3>
			<p>A nasty flaw in the React Native CLI lets attackers silently execute OS commands – potentially exposing millions of developers to remote attacks. Patch it *now*!</p>
			<div class="source">
				Source: <a href="https://thehackernews.com/2025/11/critical-react-native-cli-flaw-exposed.html" target="_blank">https://feeds.feedburner.com/TheHackersNews</a> | Published: 04 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>CISA Flags VMware Zero-Day Exploited by China-Linked Hackers in Active Attacks</h3>
			<p>Chinese hackers are actively leveraging a newly discovered VMware vulnerability (CVE-2025-41244) – a juicy 7.8 <span class="tech-jargon">CVSS<span class="jargon-expl">A scoring system to rate the severity of a vulnerability</span></span> score – to launch targeted attacks. CISA has added it to the KEV catalog, urging immediate patching.</p>
			<div class="source">
				Source: <a href="https://thehackernews.com/2025/10/cisa-flags-vmware-zero-day-exploited-by.html" target="_blank">https://feeds.feedburner.com/TheHackersNews</a> | Published: 31 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Patch Tuesday, October 2025 End of 10 Edition</h3>
			<p>Hackers are already leveraging 172 new vulnerabilities in Windows 10! Microsoft's October Patch Tuesday is a frantic scramble to close these holes before they're exploited. End of support is here – upgrade now!</p>
			<div class="source">
				Source: <a href="https://krebsonsecurity.com/2025/10/patch-tuesday-october-2025-end-of-10-edition/" target="_blank">https://krebsonsecurity.com/feed/</a> | Published: 14 Oct 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>CISA Adds Gladinet and CWP Flaws to KEV Catalog Amid Active Exploitation Evidence</h3>
			<p>Hackers are actively exploiting flaws in Gladinet and Control Web Panel (CWP). CISA’s just added them to the KEV catalog—a heads-up for anyone using these tools. Time to patch!</p>
			<div class="source">
				Source: <a href="https://thehackernews.com/2025/11/cisa-adds-gladinet-and-cwp-flaws-to-kev.html" target="_blank">https://feeds.feedburner.com/TheHackersNews</a> | Published: 05 Nov 2025
			</div>
		</div>
	</div>
	
	<div class="article">
		<div class="content">
			<h3>Truffle Security Co. TruffleHog git arbitrary code execution vulnerability</h3>
			<p><span class="tech-jargon">TruffleHog<span class="jargon-expl">A Git secrets scanning tool.</span></span>, a popular Git secrets scanning tool, had a nasty surprise: an arbitrary code execution vulnerability. Attackers could inject malicious code, highlighting the critical need for robust secret management and code review practices.</p>
			<div class="source">
				Source: <a href="https://talosintelligence.com/vulnerability_reports/TALOS-2025-2243" target="_blank">https://0dayfans.com/feed.rss</a> | Published: 19 Oct 2025
			</div>
		</div>
	</div>
	
</div>

</div>
</body>
</html>
